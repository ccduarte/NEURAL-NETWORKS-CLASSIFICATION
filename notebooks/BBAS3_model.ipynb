{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Integrado Final - Deep Learning\n",
    "\n",
    "Desenvolvimento de modelo classificação utilizando Redes Neurais Convolucionais (CNN) ou Redes Neurais Recorrentes (RNN), com base na tendencia de mercado dos ultimos 15 dias, considerando o \"close\" da ação em base de dados suavizada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Dropout, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/BBAS3.SA/treino.csv')\n",
    "df_test = pd.read_csv('../data/BBAS3.SA/teste.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo = 'BBAS3'\n",
    "# EDA\n",
    "print(f\"EDA para {nome_arquivo}:\")\n",
    "print(f\"Descrição dos dados:\\n{df_train.describe()}\\n\")\n",
    "print(f\"Contagem de valores NaN por coluna:\\n{df_train.isna().sum()}\\n\")\n",
    "print(f\"Contagem dos rótulos:\\n{df_train['Label'].value_counts()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAÇÃO ENTRE PREÇOS DE FECHAMENTO E PREÇOS DE FECHAMENTO SUAVIZADOS\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_train['Close'], label='Close')\n",
    "plt.plot(df_train['Smoothed_Close'], label='Smoothed Close')\n",
    "plt.title(f'Preços de Fechamento e Suavizados - {nome_arquivo}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTRIBUIÇÃO DOS RÓTULOS\n",
    "sns.countplot(x='Label', data=df_train)\n",
    "plt.title(f'Distribuição de Classes - {nome_arquivo}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento de modelo de Redes Neurais Recorrentes (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALIZAÇÃO DOS DADOS\n",
    "\n",
    "# Normalizador para as features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Função para converter rótulos em formato categórico\n",
    "def converter_para_categorico(y):\n",
    "    if y.min() == -1:  # Se os rótulos forem -1 e 1\n",
    "        y = (y + 1) // 2  # Converter rótulos para 0 e 1\n",
    "    return to_categorical(y)\n",
    "\n",
    "X_train = df_train.drop(['Date', 'Close', 'Smoothed_Close', 'Label'], axis=1)\n",
    "y_train = df_train['Label']\n",
    "\n",
    "X_test = df_test.drop(['Date', 'Close', 'Smoothed_Close', 'Label'], axis=1)\n",
    "y_test = df_test['Label']\n",
    "\n",
    "# Normalizar as features\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# reshape da entrada para ser [amostras, time steps, caracteristicas]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Converter os rótulos para formato categórico\n",
    "y_train_cat = converter_para_categorico(y_train)\n",
    "y_test_cat = converter_para_categorico(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria e treina a rede LSTM\n",
    "historicos = {}\n",
    "\n",
    "model_rnn = Sequential([\n",
    "        LSTM(150, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False, activation='relu'),\n",
    "        Dense(y_train_cat.shape[1], activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "# Compilando o modelo com entropia cruzada categórica para classificação binária\n",
    "# A acurácia é usada como métrica para avaliação\n",
    "model_rnn.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo com os dados\n",
    "# Epochs define o número de vezes que o modelo verá todo o conjunto de dados\n",
    "# Batch size é o número de amostras que o modelo vê antes de atualizar os pesos\n",
    "# Verbose=1 mostra a barra de progresso do treinamento\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../models/melhor_rnn_BBAS3.keras', verbose=1,  save_best_only=True, monitor='val_accuracy')\n",
    "\n",
    "historico_rnn = model_rnn.fit(X_train, y_train_cat, epochs=100, batch_size=8, validation_split=0.2, verbose=1, callbacks=[checkpointer],shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_historico(historico, titulo):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(historico.history['accuracy'], label='Acurácia de Treino')\n",
    "    if 'val_accuracy' in historico.history:\n",
    "        plt.plot(historico.history['val_accuracy'], label='Acurácia de Validação')\n",
    "    plt.plot(historico.history['loss'], label='LOSS de Treino')\n",
    "    if 'val_loss' in historico.history:\n",
    "        plt.plot(historico.history['val_loss'], label='LOSS de Validação')\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia / Perda')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotar_historico(historico_rnn, f\"Histórico de Treinamento - {nome_arquivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_rnn,show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar a matriz de confusão\n",
    "def plotar_matriz_confusao(cm, classes, title):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "\n",
    "# Avaliar o modelo\n",
    "scores = model_rnn.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"{nome_arquivo} -> Acurácia: {scores[1]*100:.2f}%\")\n",
    "\n",
    "# Predições\n",
    "y_pred = model_rnn.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_teste_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "# Gerar e plotar a matriz de confusão\n",
    "cm = confusion_matrix(y_teste_classes, y_pred_classes)\n",
    "plotar_matriz_confusao(cm, classes=['Classe 0', 'Classe 1'], title=f'Matriz de Confusão para {nome_arquivo}')\n",
    "\n",
    "# Gerar relatório de classificação\n",
    "print(f\"Relatório de Classificação para {nome_arquivo}:\\n {classification_report(y_teste_classes, y_pred_classes)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento de Redes Neurais Convolucionais (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
